#!/usr/bin/env python3
"""
Ejemplo simple de pipeline de Machine Learning con el dataset Iris
Demuestra las etapas principales: carga, preprocesamiento, entrenamiento y evaluaci√≥n
"""

import pandas as pd
import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

def main():
    print("üå∫ Pipeline de Machine Learning - Dataset Iris")
    print("=" * 50)
    
    # 1. CARGA DE DATOS
    print("\n1Ô∏è‚É£ Cargando datos...")
    iris = load_iris()
    X = iris.data  # Caracter√≠sticas (4 medidas)
    y = iris.target  # Etiquetas (3 especies)
    feature_names = iris.feature_names
    target_names = iris.target_names
    
    print(f"   ‚Ä¢ {X.shape[0]} muestras")
    print(f"   ‚Ä¢ {X.shape[1]} caracter√≠sticas: {', '.join(feature_names)}")
    print(f"   ‚Ä¢ {len(target_names)} especies: {', '.join(target_names)}")
    
    # Mostrar estad√≠sticas b√°sicas
    df = pd.DataFrame(X, columns=feature_names)
    df['species'] = [target_names[i] for i in y]
    print(f"\n   üìä Estad√≠sticas b√°sicas:")
    print(df.describe().round(2))
    
    # 2. PREPROCESAMIENTO
    print("\n2Ô∏è‚É£ Preprocesando datos...")
    
    # Separar datos de entrenamiento y evaluaci√≥n (70% - 30%)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    print(f"   ‚Ä¢ Datos de entrenamiento: {X_train.shape[0]} muestras")
    print(f"   ‚Ä¢ Datos de evaluaci√≥n: {X_test.shape[0]} muestras")
    
    # Normalizaci√≥n (escalar caracter√≠sticas para que tengan el mismo rango)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    print("   ‚Ä¢ Caracter√≠sticas normalizadas (media=0, desv_est=1)")
    
    # 3. ENTRENAMIENTO DEL MODELO
    print("\n3Ô∏è‚É£ Entrenando modelo...")
    model = SVC(kernel='linear', random_state=42)
    model.fit(X_train_scaled, y_train)
    print("   ‚Ä¢ Modelo SVM entrenado exitosamente")
    
    # 4. EVALUACI√ìN
    print("\n4Ô∏è‚É£ Evaluando modelo...")
    
    # Predicciones
    y_pred = model.predict(X_test_scaled)
    
    # M√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    print(f"   ‚Ä¢ Precisi√≥n: {accuracy:.3f} ({accuracy*100:.1f}%)")
    
    # Reporte detallado
    print(f"\n   üìä Reporte de clasificaci√≥n:")
    print(classification_report(y_test, y_pred, target_names=target_names))
    
    # Matriz de confusi√≥n
    cm = confusion_matrix(y_test, y_pred)
    print(f"\n   üî¢ Matriz de confusi√≥n:")
    print("   " + " " * 12 + "Predicci√≥n")
    print("   " + " " * 8 + "setosa versicolor virginica")
    for i, species in enumerate(target_names):
        print(f"   {species:8} {cm[i][0]:7} {cm[i][1]:10} {cm[i][2]:9}")
    
    # 5. VISUALIZACI√ìN (opcional)
    print("\n5Ô∏è‚É£ Creando visualizaci√≥n...")
    
    # Crear gr√°fico de dispersi√≥n de las dos primeras caracter√≠sticas
    plt.figure(figsize=(10, 6))
    
    # Datos de entrenamiento
    plt.subplot(1, 2, 1)
    colors = ['red', 'green', 'blue']
    for i, species in enumerate(target_names):
        mask = y_train == i
        plt.scatter(X_train[mask, 0], X_train[mask, 1], 
                   c=colors[i], label=species, alpha=0.7)
    plt.xlabel('Longitud del s√©palo (cm)')
    plt.ylabel('Ancho del s√©palo (cm)')
    plt.title('Datos de Entrenamiento')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Datos de prueba con predicciones
    plt.subplot(1, 2, 2)
    for i, species in enumerate(target_names):
        mask = y_test == i
        plt.scatter(X_test[mask, 0], X_test[mask, 1], 
                   c=colors[i], label=species, alpha=0.7, marker='o')
        # Marcar predicciones incorrectas
        wrong_mask = mask & (y_pred != y_test)
        if np.any(wrong_mask):
            plt.scatter(X_test[wrong_mask, 0], X_test[wrong_mask, 1], 
                       c='black', marker='x', s=100, label='Error' if i == 0 else "")
    
    plt.xlabel('Longitud del s√©palo (cm)')
    plt.ylabel('Ancho del s√©palo (cm)')
    plt.title('Datos de Prueba (X = Error)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('iris_classification.png', dpi=150, bbox_inches='tight')
    print("   ‚Ä¢ Gr√°fico guardado como 'iris_classification.png'")
    
    # 6. RESUMEN
    print("\n‚úÖ RESUMEN DEL PIPELINE")
    print("=" * 30)
    print(f"‚Ä¢ Dataset: {X.shape[0]} muestras de {len(target_names)} especies")
    print(f"‚Ä¢ Caracter√≠sticas: {X.shape[1]} medidas morfol√≥gicas")
    print(f"‚Ä¢ Modelo: SVM con kernel lineal")
    print(f"‚Ä¢ Precisi√≥n final: {accuracy:.1%}")
    print(f"‚Ä¢ El modelo puede clasificar correctamente {accuracy:.1%} de las flores iris")
    
    print(f"\nüéØ Este ejemplo demuestra las 6 etapas principales:")
    print("   1. Carga de datos")
    print("   2. Preprocesamiento (separaci√≥n + normalizaci√≥n)")
    print("   3. Entrenamiento del modelo")
    print("   4. Evaluaci√≥n con m√©tricas")
    print("   5. Visualizaci√≥n de resultados")
    print("   6. Interpretaci√≥n de resultados")

if __name__ == "__main__":
    main()
